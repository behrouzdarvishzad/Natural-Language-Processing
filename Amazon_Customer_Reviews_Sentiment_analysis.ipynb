{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "The Amazon Customer Reviews dataset is a valuable resource for sentiment analysis tasks. It contains a vast collection of product reviews from diverse categories, providing a rich and varied source of customer sentiments. With its extensive coverage, this dataset offers insights into the opinions and experiences of Amazon customers. By leveraging the text reviews and associated star ratings, researchers and data analysts can delve into the sentiments expressed by customers and develop models to understand and predict customer satisfaction. This dataset serves as a valuable foundation for studying customer sentiment analysis and exploring the factors that influence customer opinions on various products."
      ],
      "metadata": {
        "id": "Die4ug09wOhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset\n",
        "http://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Electronics_v1_00.tsv.gz"
      ],
      "metadata": {
        "id": "WZxsdwuCxqDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the TSV file into a DataFrame named 'data'\n",
        "data = pd.read_csv(data, delimiter='\\t', quoting=3)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKRHOgRcMAG0",
        "outputId": "ae3b0698-9a27-4c0d-efc0-837a6821ebfd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
            "0          US     41409413  R2MTG1GCZLR2DK  B00428R89M       112201306   \n",
            "1          US     49668221  R2HBOEM8LE9928  B000068O48       734576678   \n",
            "2          US     12338275  R1P4RW1R9FDPEE  B000GGKOG8       614448099   \n",
            "3          US     38487968  R1EBPM82ENI67M  B000NU4OTA        72265257   \n",
            "4          US     23732619  R372S58V6D11AT  B00JOQIO6S       308169188   \n",
            "\n",
            "                                       product_title product_category  \\\n",
            "0  yoomall 5M Antenna WIFI RP-SMA Female to Male ...      Electronics   \n",
            "1         Hosa GPM-103 3.5mm TRS to 1/4\" TRS Adaptor      Electronics   \n",
            "2        Channel Master Titan 2 Antenna Preamplifier      Electronics   \n",
            "3  LIMTECH Wall charger + USB Hotsync & Charging ...      Electronics   \n",
            "4     Skullcandy Air Raid Portable Bluetooth Speaker      Electronics   \n",
            "\n",
            "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
            "0            5              0            0    N                 Y   \n",
            "1            5              0            0    N                 Y   \n",
            "2            5              1            1    N                 Y   \n",
            "3            1              0            0    N                 Y   \n",
            "4            5              1            1    N                 Y   \n",
            "\n",
            "                 review_headline  \\\n",
            "0                     Five Stars   \n",
            "1       It works as advertising.   \n",
            "2                     Five Stars   \n",
            "3                       One Star   \n",
            "4  Overall pleased with the item   \n",
            "\n",
            "                                         review_body review_date  \n",
            "0                                      As described.  2015-08-31  \n",
            "1                           It works as advertising.  2015-08-31  \n",
            "2                                        Works pissa  2015-08-31  \n",
            "3                               Did not work at all.  2015-08-31  \n",
            "4  Works well. Bass is somewhat lacking but is pr...  2015-08-31  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use 10% of dataset"
      ],
      "metadata": {
        "id": "8Rusa0Kn-6yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = pd.read_csv('/content/dataset/amazon_reviews_us_Electronics_v1_00.tsv', delimiter='\\t', quoting=3)\n",
        "\n",
        "# Sample a subset of the data (e.g., 10% of the original dataset)\n",
        "sampled_data = data.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Display the first few rows of the sampled data\n",
        "print(sampled_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrq9hgE2-0tR",
        "outputId": "e0cd9b09-a374-4d89-e39a-fe2254f7c3d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
            "1660889          US     20454938   R5KI6FZDSUK1H  B00171MWSO       939898962   \n",
            "1354324          US     24741526  R1U6433PQBY12R  B0090Z3SPU       617888253   \n",
            "1821643          US     29123942  R2B32QV9EJUB8S  9985609034       972383144   \n",
            "2856884          US     46090876  R35MZC8Q03EMRV  B0019DKOVW       709225090   \n",
            "232973           US      5471436   R28GAE6RPKTRH  B00CVB12RG       587294791   \n",
            "\n",
            "                                             product_title product_category  \\\n",
            "1660889  Sony ICFS79W AM/FM/Weather Band Digital Tuner ...      Electronics   \n",
            "1354324         Bose SoundLink Bluetooth Mobile Speaker II      Electronics   \n",
            "1821643  Premium 50 Foot High Speed HDMI Cable for your...      Electronics   \n",
            "2856884   KICKER 08 zKICK Stereo System for Microsoft Zune      Electronics   \n",
            "232973            Brookstone 2.4GHz Wireless TV Headphones      Electronics   \n",
            "\n",
            "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
            "1660889            4              1            1    N                 Y   \n",
            "1354324            5              0            0    N                 Y   \n",
            "1821643            5              0            1    N                 Y   \n",
            "2856884            5              0            0    N                 Y   \n",
            "232973             5              1            1    N                 Y   \n",
            "\n",
            "                        review_headline  \\\n",
            "1660889    Nice quality, good reception   \n",
            "1354324               100% satisfaction   \n",
            "1821643  50 foot high speed hdmi cable.   \n",
            "2856884          Excellent speaker dock   \n",
            "232973                Hearing Difficult   \n",
            "\n",
            "                                               review_body review_date  \n",
            "1660889  We don't use it in the shower, but it is in ou...  2013-12-26  \n",
            "1354324  Great deal! I have got what I have expected. T...  2014-06-05  \n",
            "1821643  50 foot High Speed HDMI Cable:  The cable was ...  2013-09-07  \n",
            "2856884  I'm very pleased with this speaker dock. The s...  2009-02-11  \n",
            "232973     I have a difficult hearing and these help a lot  2015-06-20  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- marketplace: The country code for the marketplace where the review was posted (e.g., \"US\" for the United States).\n",
        "- customer_id: The unique identifier of the customer who posted the review.\n",
        "- review_id: The unique identifier of the review.\n",
        "- product_id: The unique identifier of the product being reviewed.\n",
        "- product_parent: The parent product identifier. Products with the same parent are variations of the same product.\n",
        "- product_title: The title or name of the product being reviewed.\n",
        "- product_category: The category to which the product belongs (e.g., \"Electronics\").\n",
        "- star_rating: The rating given by the customer (ranging from 1 to 5 stars).\n",
        "- helpful_votes: The number of helpful votes received by the review.\n",
        "- total_votes: The total number of votes (helpful and unhelpful) received by the review.\n",
        "- vine: Indicates if the review was written as part of the Vine program (an invitation-only program for trusted reviewers).\n",
        "- verified_purchase: Indicates if the review was written by a verified purchaser of the product.\n",
        "- review_headline: The headline or summary of the review.\n",
        "- review_body: The main content or body of the review.\n",
        "- review_date: The date when the review was posted.\n",
        "\n",
        "\n",
        "## Data processing"
      ],
      "metadata": {
        "id": "juxIVOFy0HXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZykYRHd4ufZ",
        "outputId": "03499191-237e-4eab-a972-3a420f9c7354"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contractions_map = {\n",
        "    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\"hasn't\": \"has not\",\"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\",\"he's\": \"he is\",\"how'd\": \"how did\",\"how'll\": \"how will\",\"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\",\"I'll\": \"I will\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\"it'd\": \"it would\",\"it'll\": \"it will\",\"it's\": \"it is\",\"let's\": \"let us\",\"mustn't\": \"must not\",\n",
        "    \"shan't\": \"shall not\",\"she'd\": \"she would\",\"she'll\": \"she will\",\"she's\": \"she is\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\"that's\": \"that is\",\"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\"they'll\": \"they will\",\"they're\": \"they are\",\"they've\": \"they have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\"we'll\": \"we will\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\"what'll\": \"what will\",\"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"where's\": \"where is\",\n",
        "    \"who'd\": \"who would\",\"who'll\": \"who will\",\"who're\": \"who are\",\"who's\": \"who is\",\"who've\": \"who have\",\"won't\": \"will not\",\"would've\": \"would have\",\"wouldn't\": \"would not\",\"you'd\": \"you would\",\n",
        "    \"you'll\": \"you will\",\"you're\": \"you are\",\"you've\": \"you have\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "3YzxTfAz8v8i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**clean_text** function now includes the expansion of contractions using the `contractions_map` dictionary"
      ],
      "metadata": {
        "id": "Yl1wQOuhCXyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to clean the review text\n",
        "def clean_text(text):\n",
        "    # Expand contractions\n",
        "    for contraction, expansion in contractions_map.items():\n",
        "        text = text.replace(contraction, expansion)\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text).lower())\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "    text = ' '.join(word for word in text.split() if word not in stopwords_set)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the review_text column\n",
        "sampled_data['review_text'] = sampled_data['review_headline'].fillna('') + ' ' + sampled_data['review_body'].fillna('')\n",
        "sampled_data['review_text'] = sampled_data['review_text'].map(clean_text)\n",
        "\n",
        "# Drop the unnecessary columns\n",
        "sampled_data.drop(columns=['review_headline', 'review_body'], inplace=True)\n",
        "\n",
        "# Display the first few rows of the processed data\n",
        "print(sampled_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl6Cg598BYlO",
        "outputId": "de08fae9-b69d-439b-f56d-dc143c590718"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
            "1660889          US     20454938   R5KI6FZDSUK1H  B00171MWSO       939898962   \n",
            "1354324          US     24741526  R1U6433PQBY12R  B0090Z3SPU       617888253   \n",
            "1821643          US     29123942  R2B32QV9EJUB8S  9985609034       972383144   \n",
            "2856884          US     46090876  R35MZC8Q03EMRV  B0019DKOVW       709225090   \n",
            "232973           US      5471436   R28GAE6RPKTRH  B00CVB12RG       587294791   \n",
            "\n",
            "                                             product_title product_category  \\\n",
            "1660889  Sony ICFS79W AM/FM/Weather Band Digital Tuner ...      Electronics   \n",
            "1354324         Bose SoundLink Bluetooth Mobile Speaker II      Electronics   \n",
            "1821643  Premium 50 Foot High Speed HDMI Cable for your...      Electronics   \n",
            "2856884   KICKER 08 zKICK Stereo System for Microsoft Zune      Electronics   \n",
            "232973            Brookstone 2.4GHz Wireless TV Headphones      Electronics   \n",
            "\n",
            "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
            "1660889            4              1            1    N                 Y   \n",
            "1354324            5              0            0    N                 Y   \n",
            "1821643            5              0            1    N                 Y   \n",
            "2856884            5              0            0    N                 Y   \n",
            "232973             5              1            1    N                 Y   \n",
            "\n",
            "        review_date                                        review_text  \n",
            "1660889  2013-12-26  nice quality good reception use shower bathroo...  \n",
            "1354324  2014-06-05  satisfaction great deal got expected speaker s...  \n",
            "1821643  2013-09-07  foot high speed hdmi cable foot high speed hdm...  \n",
            "2856884  2009-02-11  excellent speaker dock pleased speaker dock so...  \n",
            "232973   2015-06-20       hearing difficult difficult hearing help lot  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a subset of the data that has been processed according to the defined steps, including the expansion of contractions. The resulting sampled_data DataFrame will contain the relevant columns (star_rating, verified_purchase, review_text) for further analysis."
      ],
      "metadata": {
        "id": "PbeO9fh2CqQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the unnecessary columns\n",
        "sampled_data.drop(columns=['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_date'], inplace=True)\n",
        "\n",
        "# Display the first few rows of the processed data\n",
        "print(sampled_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuuFds8ZDOqm",
        "outputId": "782137a3-f1fa-4a09-86d2-076a924dc8f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         star_rating                                        review_text\n",
            "1660889            4  nice quality good reception use shower bathroo...\n",
            "1354324            5  satisfaction great deal got expected speaker s...\n",
            "1821643            5  foot high speed hdmi cable foot high speed hdm...\n",
            "2856884            5  excellent speaker dock pleased speaker dock so...\n",
            "232973             5       hearing difficult difficult hearing help lot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization\n",
        "Tokenization is the process of breaking down a text into individual words or tokens, which is an essential step in natural language processing tasks like sentiment analysis."
      ],
      "metadata": {
        "id": "lJoHtTHWDxKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsydAP5MEi1s",
        "outputId": "e4380109-83b6-49da-c9a4-ee37d1dc4efd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Tokenize the review_text column\n",
        "sampled_data['tokens'] = sampled_data['review_text'].apply(nltk.word_tokenize)\n",
        "\n",
        "# Display the first few rows of the processed data\n",
        "print(sampled_data[['review_text', 'tokens']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5qB3oxoEbNg",
        "outputId": "5d464f8e-1a26-4af2-a797-419d417b4e8f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               review_text  \\\n",
            "1660889  nice quality good reception use shower bathroo...   \n",
            "1354324  satisfaction great deal got expected speaker s...   \n",
            "1821643  foot high speed hdmi cable foot high speed hdm...   \n",
            "2856884  excellent speaker dock pleased speaker dock so...   \n",
            "232973        hearing difficult difficult hearing help lot   \n",
            "\n",
            "                                                    tokens  \n",
            "1660889  [nice, quality, good, reception, use, shower, ...  \n",
            "1354324  [satisfaction, great, deal, got, expected, spe...  \n",
            "1821643  [foot, high, speed, hdmi, cable, foot, high, s...  \n",
            "2856884  [excellent, speaker, dock, pleased, speaker, d...  \n",
            "232973   [hearing, difficult, difficult, hearing, help,...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQvIt2-QEchk",
        "outputId": "039f4ddc-a54a-4f70-8cc5-b6bd1b51bdc7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 309387 entries, 1660889 to 1431926\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   star_rating  309387 non-null  int64 \n",
            " 1   review_text  309387 non-null  object\n",
            " 2   tokens       309387 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 9.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embedding\n",
        "Word embeddings, such as Word2Vec or GloVe, require loading pre-trained models that capture the semantic meaning of words. These models can be quite large in size, and loading them into memory may exceed the available resources.\n",
        "\n",
        "Instead of using word embeddings,I use alternative text representations that are memory-efficient:\n",
        "\n",
        "**N-grams**: Instead of considering individual words, you can capture the context by using N-grams (sequences of adjacent words). N-grams can be efficient and provide more contextual information compared to individual words."
      ],
      "metadata": {
        "id": "oWxIiieGGiSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Convert the tokens column from lists to strings\n",
        "sampled_data['tokens'] = sampled_data['tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Create an instance of CountVectorizer with N-gram range (e.g., unigrams and bigrams)\n",
        "ngram_range = (1, 2)  # Adjust the range as needed (e.g., (1, 3) for unigrams, bigrams, and trigrams)\n",
        "vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
        "\n",
        "# Fit the vectorizer on the tokens column\n",
        "vectorizer.fit(sampled_data['tokens'])\n",
        "\n",
        "# Transform the tokens column into a matrix of N-gram features\n",
        "ngram_features = vectorizer.transform(sampled_data['tokens'])\n",
        "\n",
        "# Display the shape of the N-gram feature matrix\n",
        "print(\"Shape of N-gram feature matrix:\", ngram_features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1lqU-sNN-k-",
        "outputId": "dbfd70c8-fed9-4080-d75b-cb61e3b458d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of N-gram feature matrix: (309387, 3256942)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we use the CountVectorizer with the desired N-gram range (e.g., unigrams and bigrams) specified by ngram_range. I could adjust the range to include different combinations of unigrams, bigrams, trigrams, etc., by modifying the ngram_range parameter.\n",
        "\n",
        "By executing this code, we obtain the N-gram feature matrix (ngram_features), where each row represents a document from the `tokens` column, and each column corresponds to an N-gram feature.\n",
        "\n",
        "Working with N-grams can significantly increase the dimensionality of  feature space, which may impact memory usage and subsequent modeling steps.\n",
        "\n",
        "But the shape of N-gram feature matrix, (309387, 3256942), indicates that you have 309,387 samples (rows) and 3,256,942 features (columns) in the matrix. While the number of features is large, it is not uncommon in text-based analysis tasks.\n",
        "\n",
        "With the N-gram feature matrix, I train simple models to learn patterns and relationships between the features and the corresponding target variable"
      ],
      "metadata": {
        "id": "7C1Y--VTHlrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Model"
      ],
      "metadata": {
        "id": "txVio7tmaNzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = sampled_data['tokens']  # Input features (tokens column)\n",
        "y = sampled_data['star_rating']  # Target variable (star_rating column)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "q5Vh5D2JaJjh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the tokens into numerical features using a vectorization technique, such as CountVectorizer"
      ],
      "metadata": {
        "id": "mfBgutPMabiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create an instance of CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_transformed = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_transformed = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "-3OXltwUR56r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a regression model, such as Linear Regression"
      ],
      "metadata": {
        "id": "wXjTmGkBaqxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create an instance of Linear Regression model\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "regression_model.fit(X_train_transformed, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ZfrNAeUQacf2",
        "outputId": "98f1e2ff-7ba5-4b9e-bf66-6fafaff165b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the performance of the regression model"
      ],
      "metadata": {
        "id": "zATYsEr_bTzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test_transformed)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared Score:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Yg3upCbDnr",
        "outputId": "73f0f3e5-fcdd-45d8-f008-465f38b2ecea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 2.7835421091096673\n",
            "R-squared Score: -0.44277229814641217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MSE value of 2.7835 indicates the average squared difference between the predicted and actual star ratings. Lower MSE values indicate better model performance, where values closer to zero indicate a better fit to the data.\n",
        "\n",
        "The R-squared score of -0.4428 represents the coefficient of determination, which measures the proportion of variance in the target variable (star ratings) that is explained by the regression model. R-squared values range from -∞ to 1, where values closer to 1 indicate a better fit. In your case, a negative R-squared score suggests that the regression model does not fit the data well.\n",
        "\n",
        "These results indicate that the current regression model may not be performing well in predicting the star ratings."
      ],
      "metadata": {
        "id": "lhM6gQjbdQ0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "2lGpa4pqoOQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert the tokenized text to TF-IDF features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(sampled_data['tokens'])  # Replace 'tokens' with the actual column name from your dataset\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, sampled_data['star_rating'], test_size=0.2, random_state=42)  # Replace 'star_rating' with the actual column name from your dataset\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = naive_bayes.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ep82CUBoAns",
        "outputId": "7ac48c28-4c1e-4adf-b51c-2d6b9f6d5416"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.12      0.21      7167\n",
            "           2       0.00      0.00      0.00      3642\n",
            "           3       0.76      0.00      0.01      4839\n",
            "           4       0.95      0.06      0.11     10700\n",
            "           5       0.59      1.00      0.74     35530\n",
            "\n",
            "    accuracy                           0.60     61878\n",
            "   macro avg       0.64      0.24      0.21     61878\n",
            "weighted avg       0.67      0.60      0.47     61878\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MultinomialNB` is a probabilistic classifier based on the Multinomial distribution, commonly used for text classification tasks. It assumes that the features are generated from a multinomial distribution and calculates the likelihood of each class based on the occurrence frequencies of features.\n",
        "\n",
        "Class 1 (star rating 1):\n",
        "\n",
        "Precision: 0.89\n",
        "Recall: 0.12\n",
        "F1-score: 0.21\n",
        "Support: 7167\n",
        "The precision of 0.89 indicates that when the model predicts class 1, it is correct 89% of the time. However, the recall of 0.12 suggests that the model only identifies 12% of the actual instances of class 1. The low F1-score of 0.21 reflects the trade-off between precision and recall, indicating that the model struggles to accurately classify class 1.\n",
        "\n",
        "Class 2 (star rating 2):\n",
        "\n",
        "Precision: 0.00\n",
        "Recall: 0.00\n",
        "F1-score: 0.00\n",
        "Support: 3642\n",
        "The precision, recall, and F1-score for class 2 are all 0, indicating that the model does not correctly classify any instances of class 2. This suggests that the model fails to capture the patterns and characteristics of class 2.\n",
        "\n",
        "Class 3 (star rating 3):\n",
        "\n",
        "Precision: 0.76\n",
        "Recall: 0.00\n",
        "F1-score: 0.01\n",
        "Support: 4839\n",
        "The precision of 0.76 indicates that the model has moderate accuracy in predicting class 3. However, the recall of 0.00 suggests that the model does not capture any instances of class 3 effectively. The low F1-score of 0.01 further highlights the model's struggles in correctly classifying class 3.\n",
        "\n",
        "Class 4 (star rating 4):\n",
        "\n",
        "Precision: 0.95\n",
        "Recall: 0.06\n",
        "F1-score: 0.11\n",
        "Support: 10700\n",
        "The precision of 0.95 indicates that the model has a high accuracy in predicting class 4. However, the recall of 0.06 suggests that the model only identifies 6% of the actual instances of class 4. The low F1-score of 0.11 reflects the trade-off between precision and recall, indicating that the model struggles to accurately classify class 4.\n",
        "\n",
        "Class 5 (star rating 5):\n",
        "\n",
        "Precision: 0.59\n",
        "Recall: 1.00\n",
        "F1-score: 0.74\n",
        "Support: 35530\n",
        "The precision of 0.59 suggests that the model has moderate accuracy in predicting class 5. The recall of 1.00 indicates that the model captures all instances of class 5 correctly. The high F1-score of 0.74 reflects the model's ability to accurately classify class 5.\n",
        "\n",
        "Overall, the model achieves an accuracy of 0.60, which means it correctly predicts the star rating for 60% of the instances. The macro-average F1-score is 0.21, indicating the overall effectiveness of the model in correctly classifying the different classes is relatively low. The weighted average F1-score is 0.47, reflecting the trade-off between the performance of the model on different classes weighted by their respective support."
      ],
      "metadata": {
        "id": "9NQz8jCJonHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply hyperparameter tuning for the Naive Bayes model\n"
      ],
      "metadata": {
        "id": "BQBxr8YPr8du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert the tokenized text to TF-IDF features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(sampled_data['tokens'])  # Replace 'tokens' with the actual column name from your dataset\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, sampled_data['star_rating'], test_size=0.2, random_state=42)  # Replace 'star_rating' with the actual column name from your dataset\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {'alpha': [0.1, 0.5, 1.0]}  # Adjust the values as needed\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform grid search on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the Naive Bayes classifier with the best hyperparameters\n",
        "naive_bayes = MultinomialNB(**best_params)\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = naive_bayes.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO7-JsAKqy75",
        "outputId": "911dcea0-987b-4138-8647-5ab94559dd87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.70      0.53      0.60      7167\n",
            "           2       0.22      0.01      0.02      3642\n",
            "           3       0.43      0.05      0.09      4839\n",
            "           4       0.50      0.20      0.29     10700\n",
            "           5       0.67      0.97      0.79     35530\n",
            "\n",
            "    accuracy                           0.66     61878\n",
            "   macro avg       0.50      0.35      0.36     61878\n",
            "weighted avg       0.60      0.66      0.58     61878\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test a new text\n",
        "new_text = \"This product is amazing!\"\n",
        "X_new = vectorizer.transform([new_text])\n",
        "y_pred_new = naive_bayes.predict(X_new)\n",
        "\n",
        "print(\"Predicted star rating for the new text:\", y_pred_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Gvz4SaKn6i",
        "outputId": "8abb89be-7cea-4f29-c5af-06d47b49f12c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted star rating for the new text: [5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overall accuracy has increased to 66%, indicating a better classification performance.\n",
        "The precision, recall, and F1-score for each class have also improved, especially for classes 1, 3, and 4.\n",
        "The macro average and weighted average metrics have shown better scores, indicating an overall improvement in the model's performance.\n",
        "\n",
        "Here's a breakdown of the hyperparameter tuning process:\n",
        "\n",
        "Parameter Grid: First, a parameter grid is defined, `{'alpha': [0.1, 0.5, 1.0]}`which specifies the hyperparameter values to be explored. In the given example, the parameter grid consists of the alpha parameter for the MultinomialNB model.\n",
        "\n",
        "Grid Search: The GridSearchCV class from scikit-learn is used to perform grid search. It takes the model (MultinomialNB in this case), the parameter grid, and the number of cross-validation folds as input. `grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')`\n",
        "\n",
        "<img src = \"https://miro.medium.com/v2/resize:fit:786/format:webp/1*PdwlCactbJf8F8C7sP-3gw.png\">\n",
        "\n",
        "Cross-Validation: The grid search applies cross-validation on the training data. It splits the training data into multiple folds and trains/evaluates the model on different combinations of the hyperparameter values. `grid_search.fit(X_train, y_train)`\n",
        "\n",
        "Performance Evaluation: For each combination of hyperparameters, the model is trained and evaluated using the specified scoring metric (accuracy in this case). The performance metrics are recorded.\n",
        "\n",
        "`best_params = grid_search.best_params_`\n",
        "\n",
        "Best Hyperparameters: After completing the grid search, the best hyperparameters are identified based on the highest performance score. The best_params_ attribute of the grid search object provides the optimal hyperparameter values.\n",
        "\n",
        "- `naive_bayes = MultinomialNB(**best_params)`\n",
        "- `naive_bayes.fit(X_train, y_train)`\n",
        "\n",
        "Model Training and Evaluation: Finally, the Naive Bayes model is trained using the best hyperparameters, and its performance is evaluated on the test set `y_pred = naive_bayes.predict(X_test)` Make predictions on the test set\n",
        " using classification metrics such as precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "V14Su29urj-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Trees\n",
        "CountVectorizer or TF-IDF Vectorizer to convert the tokenized text into a numerical representation\n",
        "\n",
        "<img src = \"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RsrKmLuFVZcgZ3Z7sOzGKw.png\">"
      ],
      "metadata": {
        "id": "5XGGR1c_9w5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Create an instance of CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Create an instance of DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the decision tree model on the training data\n",
        "tree.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = tree.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEPB9dov7-u9",
        "outputId": "8abca5e4-1624-41c5-e580-fe55de3331ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.56      0.57      0.56      7167\n",
            "           2       0.26      0.20      0.22      3642\n",
            "           3       0.31      0.27      0.29      4839\n",
            "           4       0.38      0.37      0.38     10700\n",
            "           5       0.76      0.80      0.78     35530\n",
            "\n",
            "    accuracy                           0.62     61878\n",
            "   macro avg       0.45      0.44      0.45     61878\n",
            "weighted avg       0.61      0.62      0.61     61878\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decision tree model with CountVectorizer achieved an accuracy of 0.62 on the test set. Here's a breakdown of the classification metrics:\n",
        "\n",
        "- For class 1, the model achieved a precision of 0.56, recall of 0.57, and F1-score of 0.56.\n",
        "- For class 2, the model achieved a precision of 0.26, recall of 0.20, and F1-score of 0.22.\n",
        "- For class 3, the model achieved a precision of 0.31, recall of 0.27, and F1-score of 0.29.\n",
        "- For class 4, the model achieved a precision of 0.38, recall of 0.37, and F1-score of 0.38.\n",
        "- For class 5, the model achieved a precision of 0.76, recall of 0.80, and F1-score of 0.78.\n",
        "\n",
        "The macro average F1-score is 0.45, indicating the overall performance of the model across all classes. The weighted average F1-score is 0.61, considering the class imbalance in the dataset.\n",
        "\n",
        "Class imbalance refers to a situation where the distribution of target classes in a dataset is not balanced. In other words, one or more classes may have significantly more or fewer instances compared to the other classes. This can be problematic because machine learning algorithms often assume that the classes are balanced and may be biased towards the majority class."
      ],
      "metadata": {
        "id": "59ulKXFsGEjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSJM4g1gBUQc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}